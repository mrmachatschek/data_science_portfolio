{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Business Cases with Data Science \n",
    "\n",
    "## Case 3: Prediction of Bookings Cancellation\n",
    "\n",
    "Just Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "\n",
    "\n",
    "![alt text](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/11/How-to-Choose-Feature-Selection-Methods-For-Machine-Learning.png)\n",
    "\n",
    "\n",
    "## Methadology:\n",
    "\n",
    "Split the dataset into numerical and categorical input features and their respective target variable (\"IsCanceled\"). The notation is as followed: X (input data) = data; y (target value) = target. \n",
    "\n",
    "Apply the following steps:\n",
    " \n",
    "1. **Numerical:**\n",
    "\n",
    "1.1. RFE and Logistic Regression\n",
    "\n",
    "1.2. Lasso Regression\n",
    "\n",
    "2. **Categorical**\n",
    "\n",
    "2.1. Chi-Squared\n",
    "\n",
    "3. **Other Aproaches**\n",
    "\n",
    "3.1. Variance Threshold\n",
    "3.2. Businesswise / After Data Exploration\n",
    "\n",
    "\n",
    "**Open questions:**\n",
    "\n",
    "- Normalize Data before doing feature selection?\n",
    "- Split the dataset into Train- and Testsets? (In Lab 2 we did it just to get the right number of features; not within the RFE)\n",
    "- Can we use a Lasso-Regression for feature selection?\n",
    "- VarianceThreshold not appropriate for supervised learning?\n",
    "- How to encode the categorical variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import category_encoders as ce\n",
    "import collections\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import networkx as nx\n",
    "import plotly.offline as po \n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paste step dealing with missing values\n",
    "\n",
    "For explainability: drop all rows with nans (children: 4; Country: 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Step: divide dataset into data and target (cancellation:\"IsCanceled\")\n",
    "target = df.iloc[:,0]\n",
    "data = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Step: divide data into categorical and numerical input\n",
    "data_num = data[list(data._get_numeric_data().columns)]\n",
    "\n",
    "data_cat = data[list(set(data.columns.values) - set(data_num.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Step: split each into Training- and Testset\n",
    "# Numerical Data\n",
    "X_train_num, X_test_num, y_train_num, y_test_num = train_test_split(data_num,target, test_size = 0.3, random_state = 1)\n",
    "\n",
    "# Categorical Data\n",
    "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(data_cat,target, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Regarding the pearson and spearman correlation, no feature can be discarded because in general all variables have less correlation among each other. (see main file)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Numerical Features\n",
    "\n",
    "### 1.1. RFE with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(estimator = model, n_features_to_select = 9)\n",
    "X_rfe = rfe.fit_transform(X = data_num, y = target)\n",
    "model.fit(X=X_rfe, y = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = pd.Series(rfe.support_, index = data_num.columns)\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure out the optimal number of features (Source: Practical Lesson 2 Machine Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no of features\n",
    "nof_list=np.arange(1,13)            \n",
    "high_score=0\n",
    "#Variable to store the optimum features\n",
    "nof=0           \n",
    "score_list =[]\n",
    "for n in range(len(nof_list)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_num,target, test_size = 0.3, random_state = 0)\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    rfe = RFE(model,nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "    model.fit(X_train_rfe,y_train)\n",
    "    \n",
    "    score = model.score(X_test_rfe,y_test)\n",
    "    score_list.append(score)\n",
    "    \n",
    "    if(score>high_score):\n",
    "        high_score = score\n",
    "        nof = nof_list[n]\n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion 1.1 - RFE + LogisticRegression: \n",
    "\n",
    "#### Discard following features: \n",
    "\n",
    "1. LeadTime \n",
    "2. ArrivalDateYear\n",
    "3. ArrivalDateWeekNumber \n",
    "4. ArrivalDateDayOfMonth\n",
    "5. Children\n",
    "6. Babies\n",
    "7. DaysInWaitingList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Lasso-Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LassoCV()\n",
    "reg.fit(X=data_num, y=target)\n",
    "print(\"Best alpha: %f\" % reg.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(reg.coef_, index=data_num.columns)\n",
    "coef.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the importance (Source: Practical Lesson 2 Machine Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(coef,name):\n",
    "    imp_coef = coef.sort_values()\n",
    "    plt.figure(figsize=(8,10))\n",
    "    imp_coef.plot(kind = \"barh\")\n",
    "    plt.title(\"Feature importance using \" + name + \" Model\")\n",
    "    plt.show()\n",
    "plot_importance(coef, \"lasso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion 1.2 - Lasso Regression: \n",
    "\n",
    "#### Discard following features: \n",
    "\n",
    "1. Adults                         \n",
    "2. StaysInWeekendNights           \n",
    "3. Babies                        \n",
    "4. Children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Categorical Features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encode Categorical Data (Source: https://machinelearningmastery.com/feature-selection-with-categorical-data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare input data\n",
    "def prepare_inputs(X_train_cat, X_test_cat):\n",
    "    oe = OrdinalEncoder()\n",
    "    oe.fit(X_train_cat)\n",
    "    X_train_cat_enc = oe.transform(X_train_cat)\n",
    "    X_test_cat_enc = oe.transform(X_test_cat)\n",
    "    return X_train_cat_enc, X_test_cat_enc\n",
    " \n",
    "# prepare target\n",
    "def prepare_targets(y_train_cat, y_test_cat):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train_cat)\n",
    "    y_train_cat_enc = le.transform(y_train_cat)\n",
    "    y_test_cat_enc = le.transform(y_test_cat)\n",
    "    return y_train_cat_enc, y_test_cat_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# prepare input data\\nX_train_cat_enc, X_test_cat_enc = prepare_inputs(X_train_cat, X_test_cat)\\n# prepare output data\\ny_train_cat_enc, y_test_cat_enc = prepare_targets(y_train_cat, y_test_cat)'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# prepare input data\n",
    "X_train_cat_enc, X_test_cat_enc = prepare_inputs(X_train_cat, X_test_cat)\n",
    "# prepare output data\n",
    "y_train_cat_enc, y_test_cat_enc = prepare_targets(y_train_cat, y_test_cat)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Chi-Squared / Select K Best  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# feature selection\\ndef select_features(X_train_cat, y_train_cat, X_test_cat):\\n    fs = SelectKBest(score_func=chi2, k='all')\\n    fs.fit(X_train_cat, y_train_cat)\\n    X_train_fs = fs.transform(X_train_cat)\\n    X_test_fs = fs.transform(X_test_cat)\\n    return X_train_fs, X_test_fs, fs\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# feature selection\n",
    "def select_features(X_train_cat, y_train_cat, X_test_cat):\n",
    "    fs = SelectKBest(score_func=chi2, k='all')\n",
    "    fs.fit(X_train_cat, y_train_cat)\n",
    "    X_train_fs = fs.transform(X_train_cat)\n",
    "    X_test_fs = fs.transform(X_test_cat)\n",
    "    return X_train_fs, X_test_fs, fs\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'select_features(X_train_cat, y_train_cat, X_test_cat)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"select_features(X_train_cat, y_train_cat, X_test_cat)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for i in range(len(fs.scores_)):\\n    print('Feature %d: %f' % (i, fs.scores_[i]))\\n# plot the scores\\npyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\\npyplot.show()\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for i in range(len(fs.scores_)):\n",
    "    print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "# plot the scores\n",
    "pyplot.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "pyplot.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Other Aproaches\n",
    "\n",
    "### 3.1 VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = VarianceThreshold()\n",
    "selector.fit_transform(data_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Businesswise / After Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering:\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
